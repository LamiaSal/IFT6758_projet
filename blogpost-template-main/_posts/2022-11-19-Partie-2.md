---
layout: post
title: Partie 2
---
<h1>4. Ingénierie des caractéristiques II </h1>

<table>
  <tr>
    <th>Caractéristique</th>
    <th>Nom de la colonne</th>
    <th>Description</th>
  </tr>
  <tr>
    <td>Coordonnées</td>
    <td>x_coord et y_coord</td>
    <td>Coordonnées de l'événement</td>
  </tr>
  <tr>
    <td>Distance</td>
    <td>distance</td>
    <td>Distance entre le joueur et le but adverse</td>
  </tr>
  <tr>
    <td>Angle</td>
    <td>angle</td>
    <td>Angle entre le joueur et le but</td>
  </tr>
  <tr>
    <td>Type de tir</td>
    <td>shot_type</td>
    <td>Type du tir effectué (ex: Slap Shot)</td>
  </tr>
  <tr>
    <td>Filet désert</td>
    <td>empty_net</td>
    <td>Vrai si le filet est désert</td>
  </tr>
  <tr>
    <td>Dernier événement</td>
    <td>last_event_type</td>
    <td>Type du dernier événement (ex: Faceoff)</td>
  </tr>
  <tr>
    <td>Coordonnées du dernier événement</td>
    <td>last_x_coord et last_y_coord </td>
    <td>Coordonnées du dernier événement</td>
  </tr>
  <tr>
    <td>Distance avec le dernier événement</td>
    <td>distance_from_last</td>
    <td>Distance entre le tir et le dernier événement</td>
  </tr>
  <tr>
    <td>Temps depuis le dernier événement</td>
    <td>seconds_since_last</td>
    <td>Temps entre le tir et le dernier événement</td>
  </tr>
  <tr>
    <td>Rebond</td>
    <td>Rebound</td>
    <td>Vrai l'événement précédent est un tir</td>
  </tr>
  <tr>
    <td>Changement d'angle</td>
    <td>angle_change</td>
    <td>Différence d'angle entre ce tir et le tir précédent</td>
  </tr>
  <tr>
    <td>Vitesse</td>
    <td>speed</td>
    <td>Vitesse l'événement actuelle et le précédent </td>
  </tr>
  <tr>
    <td>Supériorité numérique</td>
    <td>powerplay</td>
    <td>Vrai, si l'équipe attaquante a plus de joueur sur la glace que l'équipe qui défend</td>
  </tr>
  <tr>
    <td>Nombre de joueurs de l'équipe attaquante</td>
    <td>team_that_shot_nb</td>
    <td>Nombre de joueurs non-gardiens de l'équipe attaquante</td>
  </tr>
  <tr>
    <td>Nombre de joueurs non-gardiens de l'équipe défendante</td>
    <td>other_team_nb</td>
    <td>Nombre de joueur de l'équipe défendante</td>
  </tr>
</table>
<h2> 4.4 Bonus: supériorité numérique </h2>
Nous avons ajouté trois caractéristiques supplémentaires qui améne de l'information sur la supériorité numérique d'une équipe par rapport à l'autre (PowerPlay) : 
- 'powerplay' : booléen définnissant si l'équipe attaquante a plus de joueurs sur la glace que l'équipe qui défend.
- 'team_that_shot_nb' : Nombre de patineurs non-gardiens de l'équipe attaquante.
- 'other_team_nb' : Nombre de patineurs non-gardiens de l'équipe défendante.

Quelques détails concernant notre implémentation:

- Nos pénalités sont calculées de sorte qu' elles soient transférables d'une période à une autre. 

- Une troisième pénalité qui ferait en sorte que moins de trois joueurs soient sur la glace est simplement ignorée. 

- Les pénalités 'Misconduct' sont elles aussi ignorées car elles n'affectent pas le nombre de joueurs sur la glace. 

- Lorsqu'un but est marqué par une équipe en supériorité numérique, la pénalité mineure ayant le moins de temps restant de l’autre équipe est annulée. 

- Similairement au point précédent, si un joueur possède plusieurs pénalités dont une mineure, deux minutes seront retranchées à son temps total. 

<h1>6. Faites de votre mieux! </h1>

<h2> Réseaux neuronaux entrainés avec toutes les caractéristiques sauf les PowerPlay</h2>

Pour entraîner les réseaux neuronaux nous avons utilisé une architecture de Multi-Layer Perceptron avec (100,50,50,20) comme dimension des couches cachées.

Modèle: [base-neuralnet-model](https://www.comet.com/princesslove/model-registry/question6-base-neuralnet-model)

Expérience: [base-neuralnet-experience](https://www.comet.com/princesslove/itf-6758-team-4/4e3809e3f5834115bbf6dabf30e2a3bb?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall)
<table>
 <tr>
    <th>Métrique</th>
    <th>Valeur</th>
  </tr>
  <tr>
    <td>Accuracy</td>
    <td>0.901</td>  
  </tr>
  <tr>
    <td>Precision</td>
    <td>0.65</td>   
  </tr>  
  <tr>
    <td>Recall</td>
    <td>0.54</td>   
  </tr>  
  <tr>
    <td>f score</td>
    <td>0.55</td>   
  </tr>  
  <tr>
    <td>AUC</td>
    <td>0.54</td>   
  </tr>  
</table>

<table>
  <tr>
    <td><img src="../assets/Part_2_Q6/Base_NN/f2.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/Base_NN/f3.svg" alt="cheese pizza"></td>  
  </tr>
  <tr>
    <td><img src="../assets/Part_2_Q6/Base_NN/f1.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/Base_NN/f4.svg" alt="cheese pizza"></td>   
  </tr>  
</table>

On observe que le réseaux neuronaux ne fonctionne pas particulièrement mieux que les autres méthodes, le réseau ne prédit que des tirs. Cela est sûrement dû au débalancement des données, il y a beaucoup plus de tir que de but.

## Essait de différent type d'échantillonnage
Pour tenter de remédier à ce problème nous avons testé 3 différentes techniques d'échantillonnage.
### Réseaux neuronaux avec sur-échantillonnage
Ici on ne fait que dupliquer assez d'exemple de but pour avoir un nombre égale de but et de tir.

Modèle: [oversampling-neuralnet-model](https://www.comet.com/princesslove/model-registry/question6-oversampling-neuralnet-model)

Expérience: [oversampling-neuralnet-experience](https://www.comet.com/princesslove/itf-6758-team-4/315fbf1d69dd4045927f172cefdc3827?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall)

<table>
 <tr>
    <th>Métrique</th>
    <th>Valeur</th>
  </tr>
  <tr>
    <td>Accuracy</td>
    <td>0.716</td>  
  </tr>
  <tr>
    <td>Precision</td>
    <td>0.559</td>   
  </tr>  
  <tr>
    <td>Recall</td>
    <td>0.646</td>   
  </tr>  
  <tr>
    <td>f score</td>
    <td>0.646</td>   
  </tr>  
  <tr>
    <td>AUC</td>
    <td>0.646</td>   
  </tr>  
</table>

<table>
  <tr>
    <td><img src="../assets/Part_2_Q6/OverSampling_NN/f2.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/OverSampling_NN/f4.svg" alt="cheese pizza"></td>  
  </tr>
  <tr>
    <td><img src="../assets/Part_2_Q6/OverSampling_NN/f1.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/OverSampling_NN/f3.svg" alt="cheese pizza"></td>   
  </tr>  
</table>
Le modèle perd en Accuracy, mais il prédit des buts! Les scores de Recall, f_score et AUC ont tous augmenté de façon considérable. Ce qui est encourageant.  
### Réseaux neuronaux avec sous-échantillonnage
Ici, on retire assez de tirs pour avoir un nombre égal de tirs et de but. 

Modèle: [undersampling-neuralnet-model](https://www.comet.com/princesslove/model-registry/question6-undersampling-neuralnet-model)

Expérience: [undersampling-neuralnet-experience](https://www.comet.com/princesslove/itf-6758-team-4/2ebb21f1bc894143a0a237d4b873c77f?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall)

<table>
 <tr>
    <th>Métrique</th>
    <th>Valeur</th>
  </tr>
  <tr>
    <td>Accuracy</td>
    <td>0.617</td>  
  </tr>
  <tr>
    <td>Precision</td>
    <td>0.541</td>   
  </tr>  
  <tr>
    <td>Recall</td>
    <td>0.618</td>   
  </tr>  
  <tr>
    <td>f score</td>
    <td>0.489</td>   
  </tr>  
  <tr>
    <td>AUC</td>
    <td>0.618</td>   
  </tr>  
</table>

<table>
  <tr>
    <td><img src="../assets/Part_2_Q6/UnderSampling_NN/f3.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/UnderSampling_NN/f1.svg" alt="cheese pizza"></td>  
  </tr>
  <tr>
    <td><img src="../assets/Part_2_Q6/UnderSampling_NN/f4.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/UnderSampling_NN/f2.svg" alt="cheese pizza"></td>   
  </tr>  
</table>
Le modèle ne prédit plus que des tirs, mais performe moins bien qu'avec le sur-échantillonnage, sûrement parce que l'on perd de l'information en retirant autant de tirs.
La technique de sur-échantillonnage semble, pour l'instant, la plus prometteuse.

### Réseaux neuronaux avec SMOTE
Ici, la méthode SMOTE permet de créer des nouveaux exemples de buts en créant de nouveaux points dans leur voisinage.

Modèle: [SMOTE-neuralnet-model](https://www.comet.com/princesslove/model-registry/question6-smote-neuralnet-model)

Expérience: [SMOTE-neuralnet-experience](https://www.comet.com/princesslove/itf-6758-team-4/b2410f1f88a747d9a0d2f08b4d266c40?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall)

<table>
 <tr>
    <th>Métrique</th>
    <th>Valeur</th>
  </tr>
  <tr>
    <td>Accuracy</td>
    <td>0.747</td>  
  </tr>
  <tr>
    <td>Precision</td>
    <td>0.561</td>   
  </tr>  
  <tr>
    <td>Recall</td>
    <td>0.636</td>   
  </tr>  
  <tr>
    <td>f score</td>
    <td>0.558</td>   
  </tr>  
  <tr>
    <td>AUC</td>
    <td>0.636</td>   
  </tr>  
</table>

<table>
  <tr>
    <td><img src="../assets/Part_2_Q6/SMOTE_NN/f4.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/SMOTE_NN/f2.svg" alt="cheese pizza"></td>  
  </tr>
  <tr>
    <td><img src="../assets/Part_2_Q6/SMOTE_NN/f3.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/SMOTE_NN/f1.svg" alt="cheese pizza"></td>   
  </tr>  
</table>
Il s'agit de la meilleure technique d'échantillonnage testée. Elle permet de calibrer le modèle afin de prédire des buts, mais d'aussi conserver une Accuracy acceptable.
 
## Ajout des caractéristiques bonus de la supériorité numérique.

Pour cette étape nous ajoutons simplement les trois caractéristiques liées aux supériorités numériques.
Pour les expériences qui suivent nous utiliserons toujours la méthode d'échantillonnage SMOTE. 

### Réseaux neuronaux avec SMOTE et la supérioté numérique

Modèle: [SMOTE-Penalties-neuralnet-model](https://www.comet.com/princesslove/model-registry/question6-smote-with-penalties-neuralnet-model)

Expérience: [SMOTE-Penalties-neuralnet-experience](https://www.comet.com/princesslove/itf-6758-team-4/074a7a6225484f55b893922c16d200c0?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall)

<table>
 <tr>
    <th>Métrique</th>
    <th>Valeur</th>
  </tr>
  <tr>
    <td>Accuracy</td>
    <td>0.762</td>  
  </tr>
  <tr>
    <td>Precision</td>
    <td>0.561</td>   
  </tr>  
  <tr>
    <td>Recall</td>
    <td>0.628</td>   
  </tr>  
  <tr>
    <td>f score</td>
    <td>0.562</td>   
  </tr>  
  <tr>
    <td>AUC</td>
    <td>0.628</td>   
  </tr>  
</table>

<table>
  <tr>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_NN/f1.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_NN/f2.svg" alt="cheese pizza"></td>  
  </tr>
  <tr>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_NN/f4.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_NN/f3.svg" alt="cheese pizza"></td>   
  </tr>  
</table>
On observe une amélioration de 2% de l'Accuracy, ainsi qu'une légère amélioration du f_score de 0.004. Prendre en compte les pénalités fonctionne!

## Calibration du seuil de prédiction

Puisque les données n'étaient pas balancées nous avons utilisé des méthodes d'échantillonnage. 
Cependant, il y a en général 10 fois moins de buts que de tirs ratés. Par conséquent, pour améliorer davantage les prédictions nous allons tenter de trouver le meilleur seuil de prédiction basé sur le f1_score.
Pour ce faire, nous testons simplement différents seuils et trouvons celui qui optimise la métrique f1_score. 
Cela a pour but de réduire le nombre de but prédit. 

 
### Réseaux neuronaux avec SMOTE, les supériorités numériques et la calibration du seuil

Le meilleur seuil de prédiction pour optimiser le f1_score a été trouvé à 0.8.

Modèle: [SMOTE-Penalties-Threshold-0.8-neuralnet-model](https://www.comet.com/princesslove/model-registry/question6-smote-with-penalties-t-0-8-neuralnet-model)

Expérience: [SMOTE-Penalties-Threshold-0.8-neuralnet-experience](https://www.comet.com/princesslove/itf-6758-team-4/c389af2961314320b5fa0bad84bdfc39?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall)

<table>
 <tr>
    <th>Métrique</th>
    <th>Valeur</th>
  </tr>
  <tr>
    <td>Accuracy</td>
    <td>0.864</td>  
  </tr>
  <tr>
    <td>Precision</td>
    <td>0.59</td>   
  </tr>  
  <tr>
    <td>Recall</td>
    <td>0.583</td>   
  </tr>  
  <tr>
    <td>f score</td>
    <td>0.583</td>   
  </tr>  
  <tr>
    <td>AUC</td>
    <td>0.583</td>   
  </tr>  
</table>

<table>
  <tr>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_T_NN/f3.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_T_NN/f2.svg" alt="cheese pizza"></td>  
  </tr>
  <tr>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_T_NN/f4.svg" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_T_NN/f1.svg" alt="cheese pizza"></td>   
  </tr>  
</table>

Matrices de confusion pour le seuil de base et le seuil optimal.
<table>
   <tr>
    <th>Seuil 0.5</th>
    <th>Seuil 0.8</th>
  </tr>  
  <tr>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_T_NN/CM.png" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q6/SMOTE_PENALTY_T_NN/CM_T.png" alt="cheese pizza"></td>  
  </tr>
</table>

On gagne 10% d'Accuracy. L'effet recherché se perçoit dans les matrices de confusions, moins de but sont prédits.
Avant environ 18 500 tirs étaient prédit comme étant des buts, maintenant seulement environ 7 000. 

Il s'agit de notre meilleur modèle pour la partie 6. 

# 7. Évaluer sur l'ensemble de test 

## 7.1 La saison régulière
Voici les résultats sur la saison régulière de 2019-2020 pour les cinq modèles.
<table>
 <tr>
    <th>Modèle</th>
    <th>Accuracy</th>
    <th>Precision</th>
    <th>Recall</th>
    <th>f score</th>
    <th>AUC</th>
  </tr>
  <tr>
    <td>LR with distance</td>
    <td>0.902</td>
    <td>0.451</td>
    <td>0.500</td>
    <td>0.474</td>
    <td>0.500</td> 
  </tr>
  <tr>
    <td>LR with angle</td>
    <td>0.902</td>
    <td>0.451</td>
    <td>0.500</td>
    <td>0.474</td>
    <td>0.500</td> 
  </tr>  
  <tr>
    <td>LR with distance and angle</td>
    <td>0.902</td>
    <td>0.451</td>
    <td>0.500</td>
    <td>0.474</td>
    <td>0.500</td>    
  </tr>  
  <tr>
    <td>XGB</td>
    <td>0.858</td>
    <td>0.606</td>
    <td>0.615</td>
    <td>0.610</td>
    <td>0.615</td>   
  </tr>  
  <tr>
    <td>NN</td>
    <td>0.869</td>
    <td>0.599</td>
    <td>0.579</td>
    <td>0.587</td>
    <td>0.579</td>   
  </tr>  
</table>
<table>
  <tr>
    <td><img src="../assets/Part_2_Q7/Regular/f1.png" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q7/Regular/f2.png" alt="cheese pizza"></td>  
  </tr>
  <tr>
    <td><img src="../assets/Part_2_Q7/Regular/f3.png" alt="cheese pizza"></td>
    <td><img src="../assets/Part_2_Q7/Regular/f4.png" alt="cheese pizza"></td>   
  </tr>  
</table>

Puisque les classes sont très débalancées nous cherchons un modèle qui a un bon f_score et un bon Recall principalement.
Selon ces critères le meilleur modèle est le XGB, il a une Accuracy quelque peu plus basse que celle du réseau neuronal, mais différencie mieux les buts tout de même.

Les trois modèles de régression linéaire sont plutôt décevants, car ils retournent tous uniquement des tirs ratés et ne peuvent distinguer aucun but, peu utile dans notre cas.

On remarque aussi que le XGB et le réseau neuronal ont des résultats similaires à ceux obtenus sur l'ensemble de validation, ce qui signifie que les deux modèles généralisent bien sur la saison régulière.














