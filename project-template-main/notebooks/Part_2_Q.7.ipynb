{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from comet_ml import API\n",
    "from dotenv import load_dotenv\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from ift6758.models.utils import preprocess, predict_model\n",
    "from ift6758.models.plotter import *\n",
    "import os\n",
    "from comet_ml import Experiment\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(register_name):\n",
    "    load_dotenv()\n",
    "    api = API()\n",
    "    # Download a Registry Model:\n",
    "    api.download_registry_model(\"princesslove\", f\"{register_name}\", \"1.0.0\",\n",
    "                                output_path=\"../comet_models/\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/file/d/1kM__riNHRPx5GsyuOH3yhiql3OZvwmuP/view?usp=sharing'\n",
    "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['season']==20192020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Downloading registry model 'question5-1-model', version '1.0.0', stage None from workspace 'princesslove'...\n",
      "COMET INFO: Unzipping model to '/Users/salhilamia/Desktop/polytechnique Montréal/Maitrise/TRIMESTRE3/Cours/IFT6758/IFT6758_projet/project-template-main/comet_models' ...\n",
      "COMET INFO: done!\n"
     ]
    }
   ],
   "source": [
    "register_name = 'question5-1-model'\n",
    "experiment_name = 'question5.1'\n",
    "download_model(register_name = register_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb_without_RDS = XGBClassifier()\n",
    "model_xgb_without_RDS.load_model(f\"../comet_models/{experiment_name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "X_test, y_test ,df_test_preprocessed =  preprocess(df_test,features = ['distance','angle'], standarize=True)\n",
    "y_test_pred_1,y_test_prob_1 = predict_model(model_xgb_without_RDS,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Downloading registry model 'question5-2-without-grid-search-model', version '1.0.0', stage None from workspace 'princesslove'...\n",
      "COMET INFO: Unzipping model to '/Users/salhilamia/Desktop/polytechnique Montréal/Maitrise/TRIMESTRE3/Cours/IFT6758/IFT6758_projet/project-template-main/comet_models' ...\n",
      "COMET INFO: done!\n"
     ]
    }
   ],
   "source": [
    "register_name = 'question5-2-without-grid-search-model'\n",
    "experiment_name = 'question5.2_without_grid_search'\n",
    "download_model(register_name = register_name )\n",
    "\n",
    "model_xgb_without_RDS = XGBClassifier()\n",
    "model_xgb_without_RDS.load_model(f\"../comet_models/{experiment_name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "list_features = ['empty_net', 'periodTime','period', 'x_coord', 'y_coord','distance','angle','shot_type',\\\n",
    "    'last_event_type', 'last_x_coord', 'last_y_coord','distance_from_last', 'seconds_since_last', \\\n",
    "        'rebound', 'angle_change','speed']\n",
    "X_test, y_test ,df_train_preprocessed =  preprocess(df_test,features = list_features, standarize=True)\n",
    "y_test_pred_2,y_test_prob_2 = predict_model(model_xgb_without_RDS,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_list= [y_test_pred_1,y_test_pred_2]\n",
    "y_test_prob_list= [y_test_prob_1,y_test_prob_2]\n",
    "\n",
    "model_names = ['model1','model2']\n",
    "\n",
    "fig = log_ROC(y_test,y_test_pred_list,model_names=model_names)\n",
    "a = log_Calibration(y_test,y_test_prob_list,model_names=model_names)\n",
    "D = log_GoalRate(y_test_prob_list,model_names=model_names)\n",
    "C = log_Cumulative(y_test_prob_list,model_names=model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO print les metrics \n",
    "\n",
    "def compute_metrics(y_true,y_preds,model_names):\n",
    "    acc=[]\n",
    "    recall = []\n",
    "    precision = []\n",
    "    f_score = []\n",
    "    for y_pred, model_name in zip(y_preds, model_names):\n",
    "        acc.append(metrics.accuracy_score(y_true,y_pred))\n",
    "        recall.append(metrics.recall_score(y_true,y_pred,average='macro'))\n",
    "        precision.append(metrics.precision_score(y_true,y_pred,average='macro'))\n",
    "        f_score.append(metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "\n",
    "    dict_data = {\n",
    "    'model_name':model_names,\n",
    "    'Accuracy':acc,\n",
    "    'Recall':recall,\n",
    "    'Precision':precision,\n",
    "    'f_score':f_score\n",
    "    }\n",
    "    return pd.DataFrame.from_dict(dict_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model1</td>\n",
       "      <td>0.903402</td>\n",
       "      <td>0.500074</td>\n",
       "      <td>0.951700</td>\n",
       "      <td>0.474772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model2</td>\n",
       "      <td>0.908201</td>\n",
       "      <td>0.533427</td>\n",
       "      <td>0.846233</td>\n",
       "      <td>0.539101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  Accuracy    Recall  Precision   f_score\n",
       "0     model1  0.903402  0.500074   0.951700  0.474772\n",
       "1     model2  0.908201  0.533427   0.846233  0.539101"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(y_test,y_test_pred_list,model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print les confusion matrix\n",
    "matrix = metrics.confusion_matrix(y_true,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift6758-conda-env",
   "language": "python",
   "name": "ift6758-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f262dd534652fbc32981d407f1a3d24b53a7b4c10afd3815e5857e898a2e9de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
