{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8daed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "dir_ = os.path.dirname(os.getcwd())\n",
    "if dir_ not in sys.path:\n",
    "    sys.path.append(dir_)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from comet_ml import Experiment\n",
    "from comet_ml import API\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set_theme()\n",
    "\n",
    "from ift6758.models.utils import preprocess, predict_model,save_metrics_and_models_on_comet,compute_metrics\n",
    "from ift6758.models.plotter import *\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import resample , shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f88441",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/file/d/1kM__riNHRPx5GsyuOH3yhiql3OZvwmuP/view?usp=sharing'\n",
    "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ae7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['season']!=20192020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1c5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_features = ['empty_net', 'periodTime','period', 'x_coord', 'y_coord','distance','angle','shot_type',\\\n",
    "    'last_event_type', 'last_x_coord', 'last_y_coord','distance_from_last', 'seconds_since_last', \\\n",
    "        'rebound', 'angle_change','speed']\n",
    "# preprocess\n",
    "X, Y ,df_train_preprocessed,_ =  preprocess(df_train,features = list_features, standarize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e76cac9",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e0cdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,Y,random_state = 42, shuffle=True)\n",
    "X_oversampled, y_oversampled = resample(X_train[y_train == 1],\n",
    "                                        y_train[y_train == 1],\n",
    "                                        replace=True,\n",
    "                                        n_samples=X_train[y_train == 0].shape[0],\n",
    "                                        random_state=42)\n",
    "\n",
    "X_train = np.vstack((X_train[y_train == 0], X_oversampled))\n",
    "y_train = np.hstack((y_train[y_train == 0], y_oversampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640794a",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5059520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,Y,random_state = 42, shuffle=True)\n",
    "X_undersampled, y_undersampled = resample(X_train[y_train == 0],\n",
    "                                          y_train[y_train == 0],\n",
    "                                          replace=True,\n",
    "                                          n_samples=X_train[y_train == 1].shape[0],\n",
    "                                           random_state=42)\n",
    "X_train = np.vstack((X_train[y_train == 1], X_undersampled))\n",
    "y_train = np.hstack((y_train[y_train == 1], y_undersampled))\n",
    "X_train, y_train = shuffle(X_train,y_train,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c6493",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb43d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 22642\n",
      "Before OverSampling, counts of label '0': 218464 \n",
      "\n",
      "After OverSampling, the shape of train_X: (436928, 30)\n",
      "After OverSampling, the shape of train_y: (436928,) \n",
      "\n",
      "After OverSampling, counts of label '1': 218464\n",
      "After OverSampling, counts of label '0': 218464\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,Y,random_state = 42, shuffle=True)\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e6fdc",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614b9880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.55581045\n",
      "Iteration 2, loss = 0.53803718\n",
      "Iteration 3, loss = 0.52972295\n",
      "Iteration 4, loss = 0.52076837\n",
      "Iteration 5, loss = 0.51124708\n",
      "Iteration 6, loss = 0.50306970\n",
      "Iteration 7, loss = 0.49796981\n",
      "Iteration 8, loss = 0.49007892\n",
      "Iteration 9, loss = 0.48294281\n",
      "Iteration 10, loss = 0.47685355\n",
      "Iteration 11, loss = 0.47117544\n",
      "Iteration 12, loss = 0.46493839\n",
      "Iteration 13, loss = 0.46118383\n",
      "Iteration 14, loss = 0.45893813\n",
      "Iteration 15, loss = 0.45455045\n",
      "Iteration 16, loss = 0.45195840\n",
      "Iteration 17, loss = 0.45099783\n",
      "Iteration 18, loss = 0.44819766\n",
      "Iteration 19, loss = 0.44694525\n",
      "Iteration 20, loss = 0.44445247\n",
      "Iteration 21, loss = 0.44327139\n",
      "Iteration 22, loss = 0.44128827\n",
      "Iteration 23, loss = 0.43960387\n",
      "Iteration 24, loss = 0.43833623\n",
      "Iteration 25, loss = 0.43773168\n",
      "Iteration 26, loss = 0.43694846\n",
      "Iteration 27, loss = 0.43583890\n",
      "Iteration 28, loss = 0.43493959\n",
      "Iteration 29, loss = 0.43344150\n",
      "Iteration 30, loss = 0.43188635\n",
      "Iteration 31, loss = 0.43073554\n",
      "Iteration 32, loss = 0.43035654\n",
      "Iteration 33, loss = 0.42927220\n",
      "Iteration 34, loss = 0.42842090\n",
      "Iteration 35, loss = 0.42737149\n",
      "Iteration 36, loss = 0.42723252\n",
      "Iteration 37, loss = 0.42697483\n",
      "Iteration 38, loss = 0.42631465\n",
      "Iteration 39, loss = 0.42530005\n",
      "Iteration 40, loss = 0.42470780\n",
      "Iteration 41, loss = 0.42403633\n",
      "Iteration 42, loss = 0.42408792\n",
      "Iteration 43, loss = 0.42387029\n",
      "Iteration 44, loss = 0.42210117\n",
      "Iteration 45, loss = 0.42123798\n",
      "Iteration 46, loss = 0.42256530\n",
      "Iteration 47, loss = 0.42168437\n",
      "Iteration 48, loss = 0.42060187\n",
      "Iteration 49, loss = 0.42006014\n",
      "Iteration 50, loss = 0.42016467\n",
      "Iteration 51, loss = 0.41910999\n",
      "Iteration 52, loss = 0.41966099\n",
      "Iteration 53, loss = 0.41870729\n",
      "Iteration 54, loss = 0.41869031\n",
      "Iteration 55, loss = 0.41819086\n",
      "Iteration 56, loss = 0.41761094\n",
      "Iteration 57, loss = 0.41679478\n",
      "Iteration 58, loss = 0.41649153\n",
      "Iteration 59, loss = 0.41729432\n",
      "Iteration 60, loss = 0.41682486\n",
      "Iteration 61, loss = 0.41634321\n",
      "Iteration 62, loss = 0.41598321\n",
      "Iteration 63, loss = 0.41526569\n",
      "Iteration 64, loss = 0.41489393\n",
      "Iteration 65, loss = 0.41551952\n",
      "Iteration 66, loss = 0.41443029\n",
      "Iteration 67, loss = 0.41423530\n",
      "Iteration 68, loss = 0.41509068\n",
      "Iteration 69, loss = 0.41452996\n",
      "Iteration 70, loss = 0.41436479\n",
      "Iteration 71, loss = 0.41368379\n",
      "Iteration 72, loss = 0.41335379\n",
      "Iteration 73, loss = 0.41290653\n",
      "Iteration 74, loss = 0.41263856\n",
      "Iteration 75, loss = 0.41355157\n",
      "Iteration 76, loss = 0.41253971\n",
      "Iteration 77, loss = 0.41261445\n",
      "Iteration 78, loss = 0.41143901\n",
      "Iteration 79, loss = 0.41174920\n",
      "Iteration 80, loss = 0.41067295\n",
      "Iteration 81, loss = 0.41103494\n",
      "Iteration 82, loss = 0.41029074\n",
      "Iteration 83, loss = 0.41019765\n",
      "Iteration 84, loss = 0.41058902\n",
      "Iteration 85, loss = 0.41031943\n",
      "Iteration 86, loss = 0.40982920\n",
      "Iteration 87, loss = 0.40980325\n",
      "Iteration 88, loss = 0.41006052\n",
      "Iteration 89, loss = 0.40952714\n",
      "Iteration 90, loss = 0.40966290\n",
      "Iteration 91, loss = 0.40912654\n",
      "Iteration 92, loss = 0.40857825\n",
      "Iteration 93, loss = 0.40831241\n",
      "Iteration 94, loss = 0.40795883\n",
      "Iteration 95, loss = 0.40859796\n",
      "Iteration 96, loss = 0.40819102\n",
      "Iteration 97, loss = 0.40822196\n",
      "Iteration 98, loss = 0.40804233\n",
      "Iteration 99, loss = 0.40776422\n",
      "Iteration 100, loss = 0.40778334\n",
      "Iteration 101, loss = 0.40758235\n",
      "Iteration 102, loss = 0.40739073\n",
      "Iteration 103, loss = 0.40735779\n",
      "Iteration 104, loss = 0.40647466\n",
      "Iteration 105, loss = 0.40647306\n",
      "Iteration 106, loss = 0.40639124\n",
      "Iteration 107, loss = 0.40637962\n",
      "Iteration 108, loss = 0.40693333\n",
      "Iteration 109, loss = 0.40634330\n",
      "Iteration 110, loss = 0.40634688\n",
      "Iteration 111, loss = 0.40581725\n",
      "Iteration 112, loss = 0.40550503\n",
      "Iteration 113, loss = 0.40507744\n",
      "Iteration 114, loss = 0.40516798\n",
      "Iteration 115, loss = 0.40578785\n",
      "Iteration 116, loss = 0.40513331\n",
      "Iteration 117, loss = 0.40441923\n",
      "Iteration 118, loss = 0.40445848\n",
      "Iteration 119, loss = 0.40441085\n",
      "Iteration 120, loss = 0.40481911\n",
      "Iteration 121, loss = 0.40434201\n",
      "Iteration 122, loss = 0.40364411\n",
      "Iteration 123, loss = 0.40360782\n",
      "Iteration 124, loss = 0.40419461\n",
      "Iteration 125, loss = 0.40352517\n",
      "Iteration 126, loss = 0.40358463\n",
      "Iteration 127, loss = 0.40346868\n",
      "Iteration 128, loss = 0.40300252\n",
      "Iteration 129, loss = 0.40269248\n",
      "Iteration 130, loss = 0.40329558\n",
      "Iteration 131, loss = 0.40274614\n",
      "Iteration 132, loss = 0.40319781\n",
      "Iteration 133, loss = 0.40245799\n",
      "Iteration 134, loss = 0.40205351\n",
      "Iteration 135, loss = 0.40205509\n",
      "Iteration 136, loss = 0.40348736\n",
      "Iteration 137, loss = 0.40169004\n",
      "Iteration 138, loss = 0.40197112\n",
      "Iteration 139, loss = 0.40201177\n",
      "Iteration 140, loss = 0.40216781\n",
      "Iteration 141, loss = 0.40192132\n",
      "Iteration 142, loss = 0.40134399\n",
      "Iteration 143, loss = 0.40144545\n",
      "Iteration 144, loss = 0.40046212\n",
      "Iteration 145, loss = 0.40128984\n",
      "Iteration 146, loss = 0.40013790\n",
      "Iteration 147, loss = 0.39984454\n",
      "Iteration 148, loss = 0.40043846\n",
      "Iteration 149, loss = 0.40030410\n",
      "Iteration 150, loss = 0.40026704\n",
      "Iteration 151, loss = 0.39994154\n",
      "Iteration 152, loss = 0.40013092\n",
      "Iteration 153, loss = 0.39903614\n",
      "Iteration 154, loss = 0.39936329\n",
      "Iteration 155, loss = 0.39898421\n",
      "Iteration 156, loss = 0.39867667\n",
      "Iteration 157, loss = 0.39898751\n",
      "Iteration 158, loss = 0.39849289\n",
      "Iteration 159, loss = 0.39853610\n",
      "Iteration 160, loss = 0.39839659\n",
      "Iteration 161, loss = 0.39738729\n",
      "Iteration 162, loss = 0.39908812\n",
      "Iteration 163, loss = 0.39801893\n",
      "Iteration 164, loss = 0.39793007\n",
      "Iteration 165, loss = 0.39778751\n",
      "Iteration 166, loss = 0.39775718\n",
      "Iteration 167, loss = 0.39709015\n",
      "Iteration 168, loss = 0.39666141\n",
      "Iteration 169, loss = 0.39757272\n",
      "Iteration 170, loss = 0.39737112\n",
      "Iteration 171, loss = 0.39754068\n",
      "Iteration 172, loss = 0.39681164\n",
      "Iteration 173, loss = 0.39654604\n",
      "Iteration 174, loss = 0.39664833\n",
      "Iteration 175, loss = 0.39632542\n",
      "Iteration 176, loss = 0.39644687\n",
      "Iteration 177, loss = 0.39606011\n",
      "Iteration 178, loss = 0.39598751\n",
      "Iteration 179, loss = 0.39626502\n",
      "Iteration 180, loss = 0.39572916\n",
      "Iteration 181, loss = 0.39596977\n",
      "Iteration 182, loss = 0.39682447\n",
      "Iteration 183, loss = 0.39610375\n",
      "Iteration 184, loss = 0.39594023\n",
      "Iteration 185, loss = 0.39539599\n",
      "Iteration 186, loss = 0.39556224\n",
      "Iteration 187, loss = 0.39545638\n",
      "Iteration 188, loss = 0.39515426\n",
      "Iteration 189, loss = 0.39532957\n",
      "Iteration 190, loss = 0.39576878\n",
      "Iteration 191, loss = 0.39545947\n",
      "Iteration 192, loss = 0.39526714\n",
      "Iteration 193, loss = 0.39544710\n",
      "Iteration 194, loss = 0.39535862\n",
      "Iteration 195, loss = 0.39471819\n",
      "Iteration 196, loss = 0.39433639\n",
      "Iteration 197, loss = 0.39480030\n",
      "Iteration 198, loss = 0.39491786\n",
      "Iteration 199, loss = 0.39464555\n",
      "Iteration 200, loss = 0.39585760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salhilamia/opt/anaconda3/envs/ift6758-conda-env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50, 50, 20), learning_rate_init=0.01,\n",
       "              random_state=1, verbose=True, warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50, 50, 20), learning_rate_init=0.01,\n",
       "              random_state=1, verbose=True, warm_start=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 50, 50, 20), learning_rate_init=0.01,\n",
       "              random_state=1, verbose=True, warm_start=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100,50,50,20),learning_rate_init=0.01,warm_start=True,random_state=1, max_iter=200,verbose=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03fba526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.757966</td>\n",
       "      <td>0.642756</td>\n",
       "      <td>0.565883</td>\n",
       "      <td>0.566772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  Accuracy    Recall  Precision   f_score\n",
       "0         NN  0.757966  0.642756   0.565883  0.566772"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_prob = model.predict_proba(X_val)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "df_metrics_results = compute_metrics(y_val,[y_val_pred],model_names=['NN'])\n",
    "df_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862ab0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/princesslove/itf-6758-team-4/770a47028599496998454370f581e427\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m name_experiment \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mquestion6_SMOTE_NeuralNet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m model_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNN\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m save_metrics_and_models_on_comet(model,y_val,y_val_pred,y_val_prob[:,\u001b[39m1\u001b[39m],model_names\u001b[39m=\u001b[39mname_experiment,model_dir\u001b[39m=\u001b[39mmodel_dir,name_experiment\u001b[39m=\u001b[39mname_experiment,register_model \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m ,sklearn_model\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/polytechnique Montréal/Maitrise/TRIMESTRE3/Cours/IFT6758/IFT6758_projet/project-template-main/ift6758/models/utils.py:35\u001b[0m, in \u001b[0;36msave_metrics_and_models_on_comet\u001b[0;34m(model, y_val, y_val_pred, y_val_prob, model_names, model_dir, name_experiment, register_model, sklearn_model)\u001b[0m\n\u001b[1;32m     33\u001b[0m     experiment\u001b[39m.\u001b[39mlog_model(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname_experiment\u001b[39m}\u001b[39;00m\u001b[39m_Model\u001b[39m\u001b[39m\"\u001b[39m, pkl_filename)\n\u001b[1;32m     34\u001b[0m \u001b[39melse\u001b[39;00m :\n\u001b[0;32m---> 35\u001b[0m     model\u001b[39m.\u001b[39;49msave_model(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../models_config/\u001b[39m\u001b[39m{\u001b[39;00mmodel_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mname_experiment\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m     experiment\u001b[39m.\u001b[39mlog_model(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname_experiment\u001b[39m}\u001b[39;00m\u001b[39m_Model\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../models_config/\u001b[39m\u001b[39m{\u001b[39;00mmodel_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mname_experiment\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[39m# log data and finish experiment\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "name_experiment = \"question6_SMOTE_NeuralNet\"\n",
    "model_dir = \"NN\"\n",
    "\n",
    "save_metrics_and_models_on_comet(model,y_val,y_val_pred,y_val_prob[:,1],model_names=name_experiment,model_dir=model_dir,name_experiment=name_experiment,register_model = True ,sklearn_model=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift6758-conda-env",
   "language": "python",
   "name": "ift6758-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
